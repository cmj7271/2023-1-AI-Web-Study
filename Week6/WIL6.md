### 1. 모델 성능의 지표
- - -

모델 성능의 지표로서, `accuracy` 정도만 알고 있었는데,  
이번 기회에 `precision`, `recall`, `f1-score` 를 알게 되었다.  
`precision`, `recall`의 경우는 모델의 예측값과 실제값을 활용한 지표이고,  
`f1-score`는 두 `precision`과 `recall` 의 조화평균이다.  
이때, 조화평균을 사용하는 이유는 같은 기준값(true-postive)으로 맞추기 위해서이다.  
`precision` 과 `recall`은 특히 데이터가 **불균형** 할 때, 효과적이다.  
- - -

### 2. 회귀
- - -

가장 먼저 활용한 `ordiary least squares` 는 우리말로 `최소제곱법`으로,  
`(모델 예측값 - 실제값)^2` 의 값이 최소가 되는 방향으로 `parameter`을 조정하는 방식이다.  
~~상세한 내용은 선형대수학을 알아야되는듯하여... 나중에 공부하는걸로~~  
그외 추가 숙제로서의 `XGBoost`, `LightGBM`, `CatBoost`의 경우 모두  
`Tree model`에 대해 `Gradiant Boosting` 한다.  
`gradiant Boosting` 의 경우 전 모델에 대한 오차값을 보완하는 방향으로 모델을 학습하는 방식이다.  
~~상세한 이론은 일단 선형대수학부터 하는 걸로;;~~  
일단 코드적으로 구현했을 때는,`CatBoost`외는 `OLS` 보다 느리게 나왔다...  
원인을 생각해보자면... 아마 과적합('overfitting')한것으로 예측된다.  
`tree` 의 깊이, `학습률` 등등의 조정이 필요해보이지만...  
어느 정도로 조정해야할지, 상세 이론을 모르니 어떤 `parameter`을 조정해야는지 알 수 없었다.  
이론에 대한 공부도 필요하겠지만, 데이터의 특성을 정확히 알고, 전처리과정도 거치는 등, 데이터에 대한 고찰이 더 필요하다고 느꼈다. 